퍼셉트론?
입력된 데이터에 어떤 처리를 가해서 y가 나오는 것 (1/0)으로 분류

z = wx + b편향 유도 활성화 가중치 입력의 곱에 편향을 더함

편향의미?
크면 쉽게 활성화, 작으면 활성화 안됨

가중치 의미?
증폭/감소 시키는것
x1, x2에 중요성을 더하기 위해 곱함

AND 게이트/

반응 조건 계산식
일반화 시켜 왼쪽으로 세타를 이항, 0

일반화?
어떤 값으로 기준 잡혀있고(0) 절대로 수식이 안바뀜  
함수를 z라고 하고

학습 목표: 수식이 유도되는 과정에 대한 이해

계단함수(선형함수)도 활성화 함수지만 너무 단순해서 사용하지 않음 (사용해도 의미가 없음)

wx+b를 행렬형태로 표현 가능

and, nand, or gate으로 단층 퍼셉트론에서 해결 할 수 없는 문제
-> 여러문제(일)으르 해결 할 수 있도록 다층 퍼셉트론을 만들

퍼셉트론보다 다양한 값을 낼수 있도록 퍼셉트론 업그레이드
각종 활성화 함수에 딷라 뉴런이 할 수 있는 일이 달라짐

=========================================================
02. 활성화 함수

1. 활성화 함수 #1 시그모이드 결과 0-1에 가까워지는 것(절대 0-1이되지는 않음)

신호강도 의미
출력층 01 로 분류될 ' 확률 '의미

히든층의 역할

2. # ReLu

음수 데이터는 영
양수 데이터는 양수 그대로 출력

그만큼 데이터가 날라가니까 과도적합의 위험이 있음 배치 노멀라이제이션으로
고정 입력값으로 얼마나 날릴지 정하는 보완점도 있음

3. 하이퍼볼릭 탄젠트 -1 ~ 1

방향(유사도) 의미하기 때문에
텍스트 분석에 많이 쓰임
 
============================================================
04. 입력값과 가중치
to to from

신경망에서 내적이 사용되는 이유?
z는 몇개인가?

뉴런마다 입력 받는 가중치 2개씩 입력받는 3종류의 뉴런이 있음
결과물 3개  

내적이 불가능하면 입력을 못받는다는 의미임->그래서 입력의 shape을 꼭 보아야 함!!

w 가중치는
b는 뉴런의 갯수만큼 필요함
z는 3개

<< 공부방법>>
시그모이드는 눈으로 넘겨도 괜찮지만
배열, 수식은 꼭 손으로 여러번 적을 것!!!고
도식 유닛 그림 직접 그리며 이해하기
후에 - > 코딩으로 직접 구현 해보기

<shape의 확인>
배열은 꼭 쉐입을 찍어서 확인해볼것!! 그리고 신경망을 공부하고 내적 편향을 구하는 등 공부해야함


출력을 어떻게 할 것인가?

출력층 의해서 사용처가 달라짐
히든층에는 다른걸 사용해도 된다?

항등함수(회귀 분석 - 출력층에서 identity function 놓고 , loss 는 MSE 씀)
시그모이드(분류 분석) 0, 1 (1번 클래스가 될 수 있는) 확률
소프트맥스 함수

==================================================================
분류모델(가중치와 신경망의 데이터 더 깊은 이해가 필요) <=> 생성모델?? 흑백사진 색깔 칠하는 것???

인코더 디코더의 개념-
신경망 생성 모델에서 사용되는 모델의 특징
컨텍스트 백터, 디코더의 개념
 
1) 자연어 처리 -> 트랜스포머 (번역기 만드는 것)
self atteion bottom up attention _> sequence> attention
beam search> bunt algorithm GPT2,3(자연어 생성 오픈  API)

2) GAN - 픽셀이 찍여야 할 거라서 확률 공부가 중요해짐
 
소프트맥스의 심도깊은 이해가 필요함
소프트맥스가 출력층이 아닌 은닉층에 쓰임

뉴련 여러개 놓고

이진분류때는 사실
합성곱 G.모델등

====================
5. 출력층 설계

소프트맥스 함수

단조 함수는 참고/튜닝도 넘기고/수식 (부분/전체)

몇개의 클래스를 분류하든 전체의 총합은 1
각 클래스의 확률 의미

텍스트 분석(토큰)
다음에 어떤 시퀀스가 나올지 확률은 재준다..

신경망에 넣을 준비 - 어떤 레이어가 무슨 역할을 하는지.. -


전결합 예측 dense layer의 사용처는 추론
affine layer가 그 예가 됨
정결합계층의 예측


배치에 대한 reshape을 flatten layer을 쓰기도 함 알아서 평탄화 해줌
가중치 정보를 활용해서 예측하는 코드 만듬

내적의 여부를 판단한 후 신경망의 모습을 생각해주면 된다..
한장의 예측, 배치 예측
========================

06. 손실함수
어떤 판단의 기준을 위해 수치로 정량화 한것
잘 못맞춘 것을 기준으로 설명해줌
accuracy를 같이 보지 않음

손실함수에 accuracy(정확도)를 놓지 않음 놓지 않는 이유.. 재현율, 정밀도 문제로(어떤 문제였지?)

MSE에서 1/n이 아닌 1/2을 쓰는 이유?
미분하기 쉬우니까 1/n보다 오차는 크지만 갱신을 많이 하면 됨

도함수? 미분값을 구하기 위한 식
x^2= 2x

3x + 3의 도함수는 어떻게 구함? => 3
MSE의 도함수를 구하면(=미분하면?) (y-t)만 남게 됨
각 뉴런의 오차를 구함

교차엔트로피 MSE의 차이점?
크로스엔트로피는 오차가 클수록 로스 크고, 작을 수록


<미니배치>

배치별로 코드
배치 평균 손실 -> 배치별 손실 (1/n)

<엑시스 이해가 중요>
어떤 방향으로 둘 건지

배열 손으로 그려보기!!

dy/ dx
x에 대한 "y의 변화량"


=====
< 전방 중앙차분을 활용한 미분>

f(x)를 기준으로 똑같은 거리만큼 앞뒤에 간 f(x-h), f(x+h)의 기울기를 재게 되는
f(x) 접선의 평행이동이 가능해서 실제의 기울기가 실제 접선의 기울기와 같다고 가정할 수 있음...

<편미분>
인수가 2개 이상일 때
한쪽 방향으로 미분하는 것

델타 라운드 파샬
편미분이기 때문에 델타기호를 쓰지 d를 쓰지 않음

수식 유도를 할줄 알아야 함
그래서 그려야함

f(x)의 편미분 도함수를 구해봄 소식 ->f`(x0) f1
패드 잘못되면 또 지우니까.. 패드에 쓰지 말것.. 잘못된것도 지우개 버튼 찾는 시간도 아껴!!!
시간을 아껴라!!!

구한 기울기들을 모은것을 벡터!라고 함(기울기들을 백터화 시킴, 기울기들을 배열)

<경사하강법>에 의해 학습률 계산
학습률(얼만큼 갱신해야할까 조절해주는것)

경사하강법 수식과 코드를 계속 보기를!! 바람!!!

기울기와 편향 갱신되는 모습을 참고하고 좌표를 찍어봤고,
(이런 코드는 한번만 보고)

이런 신경망 가중치의 배열
숫자 하나다 읽어보고 그림을 다 그려보기!!
(2,3)
입력갑 2개인 클래스 종류 3개인 배열

최적화 -> loss를 최소화 하기 위한 가중치와 편향을 구하는 과정

미분값이 필요해서 미분을 한거임 구해야함
수치미분을 했더니 넘 느리니까 오차역전파를 하게 됌!


=====================================================
09. 역전파 구현
입력값을 받으면 순전파
미분값을 전파하면 역전파

Affine layer
행렬의 내전 wx+b
을 위한 최적 도구는 Class

ordered dict 쓰는 이유?
레이어가 추가된 순서대로 실행되기 위해서

생각 안하고 쓴것 ctrl cv

코드는 개념이 아님(엔지니어링이 아니라 학문!!)
그래서 개념을 이해하고 써먹을 줄 알아야함!!!
1-8장 원리이해 후 인사이트 찾아내어 9장에서
그 느낌이 있어.. 이렇게 되겠구나..
그 이유는 옛날에 다 했던걸 지독스럽게 연습했기 때문에!! 응용가능!

레이어를 엮어내는 것 중요
순전파 - 입력값을 넣고 여러 레이어를 통해 예측값 y를 내는 과정 -> predict  / 
오차 구하는 것 손실 함수 (y-t)를 그대로 전달하면 오차 역전파가 되는 것임!!

2..0
순전파 - 꺼내서 순서대로 forwarding했음
역전파 - 꺼내서 뒤집은 다음 backward

순전파 -입력값을 넣어주고 ???
역전파- 미분값을 넣어주는 거고

도함수 읽어내는 능력 중요!
도함수 도축해 내는 능력!! 나중에 중요해짐 -> 수학 해야하는 이유..

미분값이 (미분값을 구하는 것)

돈통과 포스기의 관계는 1
곱셈노드로 도함수를 구할 수 있음
